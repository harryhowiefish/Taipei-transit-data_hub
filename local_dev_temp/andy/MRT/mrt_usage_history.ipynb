{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "from sqlalchemy import create_engine, exc\n",
    "from zoneinfo import ZoneInfo\n",
    "from io import StringIO\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "# mrt_usage_history\n",
    "# get csv download of every month's data\n",
    "# each url can get one month's data\n",
    "\n",
    "\n",
    "def E_mrt_usage_history_csvfilelist():\n",
    "    url = \"https://data.taipei/api/dataset/63f31c7e-7fc3-418b-bd82-b95158755b4d/resource/eb481f58-1238-4cff-8caa-fa7bb20cb4f4/download\"\n",
    "    response = requests.get(url=url)\n",
    "    response_list = response.text.split(\"\\r\")\n",
    "\n",
    "    col_name = response_list[0].split(\",\")\n",
    "    url_df = pd.concat([pd.DataFrame([response_list[i].split(\n",
    "        \",\")[1:]], columns=col_name[1:]) for i in range(1, len(response_list))], axis=0)\n",
    "    url_df.reset_index(drop=True, inplace=True)\n",
    "    print(\"E_mrt_usage_history_csvfilelist finished\")\n",
    "    return (url_df)\n",
    "\n",
    "\n",
    "# def T_mrt_usage_history_one_month_apply_reduce(url):\n",
    "#     response = requests.get(url=url)\n",
    "#     StringIO_df = StringIO(response.content.decode(\"utf-8-sig\"))\n",
    "#     df = pd.read_csv(StringIO_df)\n",
    "#     pattern = re.compile(r\"[A-Za-z]+\")\n",
    "#     df[\"進站\"] = df[\"進站\"].str.replace(pattern, \"\", regex=True)\n",
    "#     df[\"出站\"] = df[\"出站\"].str.replace(pattern, \"\", regex=True)\n",
    "#     df_enter = pd.DataFrame(df.groupby([\"日期\", \"時段\", \"進站\"])[\n",
    "#                             \"人次\"].sum()).reset_index(drop=False)\n",
    "#     df_out = pd.DataFrame(df.groupby([\"日期\", \"時段\", \"出站\"])[\n",
    "#         \"人次\"].sum()).reset_index(drop=False)\n",
    "#     df_enter.rename(columns={\n",
    "#         \"日期\": \"date\",\n",
    "#         \"時段\": \"hour\",\n",
    "#         \"進站\": \"mrt_station_name\",\n",
    "#         \"人次\": \"enter_count\"\n",
    "#     }, inplace=True)\n",
    "\n",
    "#     df_out.rename(columns={\n",
    "#         \"日期\": \"date\",\n",
    "#         \"時段\": \"hour\",\n",
    "#         \"出站\": \"mrt_station_name\",\n",
    "#         \"人次\": \"exit_count\"\n",
    "#     }, inplace=True)\n",
    "#     df = df_enter.merge(df_out,\n",
    "#                         left_on=[\"date\", \"hour\", \"mrt_station_name\"],\n",
    "#                         right_on=[\"date\", \"hour\", \"mrt_station_name\"],\n",
    "#                         how=\"outer\")\n",
    "#     print(\"T_mrt_usage_history_one_month finished\")\n",
    "#     return (df)\n",
    "\n",
    "\n",
    "def T_mrt_usage_history_one_month(url: str):\n",
    "    response = requests.get(url=url)\n",
    "    StringIO_df = StringIO(response.content.decode(\"utf-8-sig\"))\n",
    "    df = pd.read_csv(StringIO_df)\n",
    "    pattern = re.compile(r\"[A-Za-z]+\")\n",
    "    df[\"進站\"] = df[\"進站\"].str.replace(pattern, \"\", regex=True)\n",
    "    df[\"出站\"] = df[\"出站\"].str.replace(pattern, \"\", regex=True)\n",
    "    df.rename(columns={\n",
    "        \"日期\": \"date\",\n",
    "        \"時段\": \"hour\",\n",
    "        \"進站\": \"mrt_station_name_enter\",\n",
    "        \"出站\": \"mrt_station_name_exit\",\n",
    "        \"人次\": \"visitors_num\"\n",
    "    }, inplace=True)\n",
    "    print(f\"T_mrt_usage_history finished\")\n",
    "    return (df)\n",
    "\n",
    "\n",
    "def T_mrt_usage_history_one_month_recuce(df: pd.DataFrame):\n",
    "    df_enter = pd.DataFrame(df.groupby([\"date\", \"hour\", \"mrt_station_name_enter\"])[\n",
    "                            \"visitors_num\"].sum()).reset_index(drop=False)\n",
    "    df_out = pd.DataFrame(df.groupby([\"date\", \"hour\", \"mrt_station_name_exit\"])[\n",
    "        \"visitors_num\"].sum()).reset_index(drop=False)\n",
    "    df = df_enter.merge(df_out,\n",
    "                        left_on=[\"date\", \"hour\", \"mrt_station_name_enter\"],\n",
    "                        right_on=[\"date\", \"hour\", \"mrt_station_name_exit\"],\n",
    "                        how=\"outer\", suffixes=[\"_enter\", \"_exit\"])\n",
    "    df[\"mrt_station_name\"] = df[\"mrt_station_name_exit\"].combine_first(\n",
    "        df[\"mrt_station_name_enter\"])\n",
    "    df = df.loc[:, [\"date\", \"hour\", \"mrt_station_name\",\n",
    "                    \"visitors_num_enter\", \"visitors_num_exit\"]]\n",
    "    return (df)\n",
    "\n",
    "\n",
    "def L_mrt_usage_history(df: pd.DataFrame):\n",
    "    username_sql = os.getenv(\"ANDY_USERNAME_SQL\")\n",
    "    password_sql = os.getenv(\"ANDY_PASSWORD_SQL\")\n",
    "    # server = \"host.docker.internal:3306\"  #docker用\n",
    "    server = \"localhost:3306\"\n",
    "    db_name = \"group2_db\"\n",
    "    try:\n",
    "        with create_engine(f\"mysql+pymysql://{username_sql}:{password_sql}@{server}/{db_name}\",).connect() as conn:\n",
    "            df.to_sql(\n",
    "                name=\"mrt_usage_history\",\n",
    "                con=conn,\n",
    "                if_exists=\"append\",\n",
    "                index=False\n",
    "            )\n",
    "        print(f\"L_mrt_usage_history finished\")\n",
    "        return (\"L_mrt_usage_history finished\")\n",
    "    except:\n",
    "        print(\"loading to sql fail\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_mrt_usage_history_csvfilelist finished\n"
     ]
    }
   ],
   "source": [
    "url_df = E_mrt_usage_history_csvfilelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>年月</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>http://tcgmetro.blob.core.windows.net/stationo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201702</td>\n",
       "      <td>http://tcgmetro.blob.core.windows.net/stationo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201703</td>\n",
       "      <td>http://tcgmetro.blob.core.windows.net/stationo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201704</td>\n",
       "      <td>http://tcgmetro.blob.core.windows.net/stationo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201705</td>\n",
       "      <td>http://tcgmetro.blob.core.windows.net/stationo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>202312</td>\n",
       "      <td>http://tcgmetro.blob.core.windows.net/stationo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>202401</td>\n",
       "      <td>http://tcgmetro.blob.core.windows.net/stationo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>202402</td>\n",
       "      <td>http://tcgmetro.blob.core.windows.net/stationo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>202403</td>\n",
       "      <td>http://tcgmetro.blob.core.windows.net/stationo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>202404</td>\n",
       "      <td>http://tcgmetro.blob.core.windows.net/stationo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        年月                                                URL\n",
       "0   201701  http://tcgmetro.blob.core.windows.net/stationo...\n",
       "1   201702  http://tcgmetro.blob.core.windows.net/stationo...\n",
       "2   201703  http://tcgmetro.blob.core.windows.net/stationo...\n",
       "3   201704  http://tcgmetro.blob.core.windows.net/stationo...\n",
       "4   201705  http://tcgmetro.blob.core.windows.net/stationo...\n",
       "..     ...                                                ...\n",
       "83  202312  http://tcgmetro.blob.core.windows.net/stationo...\n",
       "84  202401  http://tcgmetro.blob.core.windows.net/stationo...\n",
       "85  202402  http://tcgmetro.blob.core.windows.net/stationo...\n",
       "86  202403  http://tcgmetro.blob.core.windows.net/stationo...\n",
       "87  202404  http://tcgmetro.blob.core.windows.net/stationo...\n",
       "\n",
       "[88 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "GCS_CREDENTIALS_FILE_PATH = r\"D:\\data_engineer\\dev_TIR_group2\\Taipei-transit-data_hub\\airflow\\dags\\harry_GCS_BigQuery_write_cred.json\"\n",
    "#GCS_CREDENTIALS_FILE_PATH = r\"C:\\dev_TIR101\\Taipei-transit-data_hub\\airflow\\dags\\harry_GCS_BigQuery_write_cred.json\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GCS_CREDENTIALS_FILE_PATH\n",
    "GCS_CLIENT = storage.Client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_bucket_string(df: pd.DataFrame, blob_name: str, bucket_name: str, storage_client: storage.Client):\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    csv_string = df.to_csv(index=False, encoding=\"utf-8-sig\")\n",
    "    blob.upload_from_string(csv_string)\n",
    "    print(blob)\n",
    "    return blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_df_to_gcs(\n",
    "    client: storage.Client,\n",
    "    bucket_name: str,\n",
    "    blob_name: str,\n",
    "    df: pd.DataFrame,\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Upload a pandas dataframe to GCS.\n",
    "\n",
    "    Args:\n",
    "        client (storage.Client): The client to use to upload to GCS.\n",
    "        bucket_name (str): The name of the bucket to upload to.\n",
    "        blob_name (str): The name of the blob to upload to.\n",
    "        df (pd.DataFrame): The dataframe to upload.\n",
    "        filetype (str): The type of the file to download. Default is \"parquet\".\n",
    "                        Can be \"parquet\" or \"csv\" or \"jsonl\".\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the upload was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    bucket = client.bucket(bucket_name)\n",
    "\n",
    "    blob = bucket.blob(blob_name)\n",
    "    if blob.exists():\n",
    "        print(\"File already exists in GCP.\")\n",
    "        return False\n",
    "    try:\n",
    "        blob.upload_from_string(\n",
    "            df.to_csv(index=False), content_type=\"text/csv\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to upload pd.DataFrame to GCS, reason: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_mrt_usage_history_one_month(url: str):\n",
    "    response = requests.get(url=url)\n",
    "    StringIO_df = StringIO(response.content.decode(\"utf-8-sig\"))\n",
    "    df = pd.read_csv(StringIO_df)\n",
    "    pattern = re.compile(r\"[A-Za-z]+\")\n",
    "    # df[\"進站\"] = df[\"進站\"].str.replace(pattern, \"\", regex=True)\n",
    "    # df[\"出站\"] = df[\"出站\"].str.replace(pattern, \"\", regex=True)\n",
    "    df.rename(columns={\n",
    "        \"日期\": \"date\",\n",
    "        \"時段\": \"hour\",\n",
    "        \"進站\": \"mrt_station_name_enter\",\n",
    "        \"出站\": \"mrt_station_name_exit\",\n",
    "        \"人次\": \"visitors_num\"\n",
    "    }, inplace=True)\n",
    "    print(f\"T_mrt_usage_history finished\")\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_month = url_df[url_df[\"年月\"]==\"201904\"].index.tolist()[0]\n",
    "start_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201904  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201904 download finished\n",
      "201904 is being uploaded to GCS\n",
      "201904 has been sucessfully uploaded to GCS\n",
      "201903  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201903 download finished\n",
      "201903 is being uploaded to GCS\n",
      "201903 has been sucessfully uploaded to GCS\n",
      "201902  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201902 download finished\n",
      "201902 is being uploaded to GCS\n",
      "201902 has been sucessfully uploaded to GCS\n",
      "201901  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201901 download finished\n",
      "201901 is being uploaded to GCS\n",
      "201901 has been sucessfully uploaded to GCS\n",
      "201812  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201812 download finished\n",
      "201812 is being uploaded to GCS\n",
      "201812 has been sucessfully uploaded to GCS\n",
      "201811  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201811 download finished\n",
      "201811 is being uploaded to GCS\n",
      "201811 has been sucessfully uploaded to GCS\n",
      "201810  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201810 download finished\n",
      "201810 is being uploaded to GCS\n",
      "201810 has been sucessfully uploaded to GCS\n",
      "201809  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201809 download finished\n",
      "201809 is being uploaded to GCS\n",
      "201809 has been sucessfully uploaded to GCS\n",
      "201808  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201808 download finished\n",
      "201808 is being uploaded to GCS\n",
      "201808 has been sucessfully uploaded to GCS\n",
      "201807  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201807 download finished\n",
      "201807 is being uploaded to GCS\n",
      "201807 has been sucessfully uploaded to GCS\n",
      "201806  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201806 download finished\n",
      "201806 is being uploaded to GCS\n",
      "201806 has been sucessfully uploaded to GCS\n",
      "201805  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201805 download finished\n",
      "201805 is being uploaded to GCS\n",
      "201805 has been sucessfully uploaded to GCS\n",
      "201804  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201804 download finished\n",
      "201804 is being uploaded to GCS\n",
      "201804 has been sucessfully uploaded to GCS\n",
      "201803  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201803 download finished\n",
      "201803 is being uploaded to GCS\n",
      "201803 has been sucessfully uploaded to GCS\n",
      "201802  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201802 download finished\n",
      "201802 is being uploaded to GCS\n",
      "201802 has been sucessfully uploaded to GCS\n",
      "201801  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201801 download finished\n",
      "201801 is being uploaded to GCS\n",
      "201801 has been sucessfully uploaded to GCS\n",
      "201712  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201712 download finished\n",
      "201712 is being uploaded to GCS\n",
      "201712 has been sucessfully uploaded to GCS\n",
      "201711  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201711 download finished\n",
      "201711 is being uploaded to GCS\n",
      "201711 has been sucessfully uploaded to GCS\n",
      "201710  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201710 download finished\n",
      "201710 is being uploaded to GCS\n",
      "201710 has been sucessfully uploaded to GCS\n",
      "201709  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201709 download finished\n",
      "201709 is being uploaded to GCS\n",
      "201709 has been sucessfully uploaded to GCS\n",
      "201708  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201708 download finished\n",
      "201708 is being uploaded to GCS\n",
      "201708 has been sucessfully uploaded to GCS\n",
      "201707  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201707 download finished\n",
      "201707 is being uploaded to GCS\n",
      "201707 has been sucessfully uploaded to GCS\n",
      "201706  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201706 download finished\n",
      "201706 is being uploaded to GCS\n",
      "201706 has been sucessfully uploaded to GCS\n",
      "201705  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201705 download finished\n",
      "201705 is being uploaded to GCS\n",
      "201705 has been sucessfully uploaded to GCS\n",
      "201704  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201704 download finished\n",
      "201704 is being uploaded to GCS\n",
      "201704 has been sucessfully uploaded to GCS\n",
      "201703  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201703 download finished\n",
      "201703 is being uploaded to GCS\n",
      "201703 has been sucessfully uploaded to GCS\n",
      "201702  is downloading\n",
      "T_mrt_usage_history finished\n",
      "201702 download finished\n",
      "201702 is being uploaded to GCS\n",
      "201702 has been sucessfully uploaded to GCS\n"
     ]
    }
   ],
   "source": [
    "for i in range(start_month,0,-1):\n",
    "    month = url_df.loc[i, \"年月\"]\n",
    "    url = url_df.loc[i, \"URL\"]\n",
    "    print(f\"{month}  is downloading\")\n",
    "    df = E_mrt_usage_history_one_month(url=url)\n",
    "    print(f\"{month} download finished\")\n",
    "    print(f\"{month} is being uploaded to GCS\")\n",
    "    # upload_to_bucket_string(\n",
    "    #     df=df, bucket_name=\"mrt_history_usage\", blob_name=f\"{month}_mrt_history_usage.csv\", storage_client=GCS_CLIENT)\n",
    "    upload_df_to_gcs(\n",
    "        client=GCS_CLIENT,\n",
    "        bucket_name=\"mrt_history_usage\",\n",
    "        blob_name=f\"{month}_mrt_history_usage.csv\",\n",
    "        df=df,\n",
    "    ) \n",
    "    print(f\"{month} has been sucessfully uploaded to GCS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'202404_mrt_history_usage.csv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{month}_mrt_history_usage.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_df_to_gcs(\n",
    "    client=GCS_CLIENT,\n",
    "    bucket_name=\"mrt_history_usage\",\n",
    "    blob_name=f\"{month}_mrt_history_usage.csv\",\n",
    "    df=df,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202403 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202403 download finished\n",
      "202403 saving csv\n",
      "202403 csv has been saved\n",
      "202403 reducing(group by)\n",
      "202403 reducing file has been saved\n",
      "202402 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202402 download finished\n",
      "202402 saving csv\n",
      "202402 csv has been saved\n",
      "202402 reducing(group by)\n",
      "202402 reducing file has been saved\n",
      "202401 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202401 download finished\n",
      "202401 saving csv\n",
      "202401 csv has been saved\n",
      "202401 reducing(group by)\n",
      "202401 reducing file has been saved\n",
      "202312 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202312 download finished\n",
      "202312 saving csv\n",
      "202312 csv has been saved\n",
      "202312 reducing(group by)\n",
      "202312 reducing file has been saved\n",
      "202311 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202311 download finished\n",
      "202311 saving csv\n",
      "202311 csv has been saved\n",
      "202311 reducing(group by)\n",
      "202311 reducing file has been saved\n",
      "202310 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202310 download finished\n",
      "202310 saving csv\n",
      "202310 csv has been saved\n",
      "202310 reducing(group by)\n",
      "202310 reducing file has been saved\n",
      "202309 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202309 download finished\n",
      "202309 saving csv\n",
      "202309 csv has been saved\n",
      "202309 reducing(group by)\n",
      "202309 reducing file has been saved\n",
      "202308 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202308 download finished\n",
      "202308 saving csv\n",
      "202308 csv has been saved\n",
      "202308 reducing(group by)\n",
      "202308 reducing file has been saved\n",
      "202307 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202307 download finished\n",
      "202307 saving csv\n",
      "202307 csv has been saved\n",
      "202307 reducing(group by)\n",
      "202307 reducing file has been saved\n",
      "202306 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202306 download finished\n",
      "202306 saving csv\n",
      "202306 csv has been saved\n",
      "202306 reducing(group by)\n",
      "202306 reducing file has been saved\n",
      "202305 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202305 download finished\n",
      "202305 saving csv\n",
      "202305 csv has been saved\n",
      "202305 reducing(group by)\n",
      "202305 reducing file has been saved\n",
      "202304 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202304 download finished\n",
      "202304 saving csv\n",
      "202304 csv has been saved\n",
      "202304 reducing(group by)\n",
      "202304 reducing file has been saved\n",
      "202303 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202303 download finished\n",
      "202303 saving csv\n",
      "202303 csv has been saved\n",
      "202303 reducing(group by)\n",
      "202303 reducing file has been saved\n",
      "202302 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202302 download finished\n",
      "202302 saving csv\n",
      "202302 csv has been saved\n",
      "202302 reducing(group by)\n",
      "202302 reducing file has been saved\n",
      "202301 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202301 download finished\n",
      "202301 saving csv\n",
      "202301 csv has been saved\n",
      "202301 reducing(group by)\n",
      "202301 reducing file has been saved\n",
      "202212 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202212 download finished\n",
      "202212 saving csv\n",
      "202212 csv has been saved\n",
      "202212 reducing(group by)\n",
      "202212 reducing file has been saved\n",
      "202211 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202211 download finished\n",
      "202211 saving csv\n",
      "202211 csv has been saved\n",
      "202211 reducing(group by)\n",
      "202211 reducing file has been saved\n",
      "202210 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202210 download finished\n",
      "202210 saving csv\n",
      "202210 csv has been saved\n",
      "202210 reducing(group by)\n",
      "202210 reducing file has been saved\n",
      "202209 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202209 download finished\n",
      "202209 saving csv\n",
      "202209 csv has been saved\n",
      "202209 reducing(group by)\n",
      "202209 reducing file has been saved\n",
      "202208 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202208 download finished\n",
      "202208 saving csv\n",
      "202208 csv has been saved\n",
      "202208 reducing(group by)\n",
      "202208 reducing file has been saved\n",
      "202207 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202207 download finished\n",
      "202207 saving csv\n",
      "202207 csv has been saved\n",
      "202207 reducing(group by)\n",
      "202207 reducing file has been saved\n",
      "202206 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202206 download finished\n",
      "202206 saving csv\n",
      "202206 csv has been saved\n",
      "202206 reducing(group by)\n",
      "202206 reducing file has been saved\n",
      "202205 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202205 download finished\n",
      "202205 saving csv\n",
      "202205 csv has been saved\n",
      "202205 reducing(group by)\n",
      "202205 reducing file has been saved\n",
      "202204 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202204 download finished\n",
      "202204 saving csv\n",
      "202204 csv has been saved\n",
      "202204 reducing(group by)\n",
      "202204 reducing file has been saved\n",
      "202203 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202203 download finished\n",
      "202203 saving csv\n",
      "202203 csv has been saved\n",
      "202203 reducing(group by)\n",
      "202203 reducing file has been saved\n",
      "202202 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202202 download finished\n",
      "202202 saving csv\n",
      "202202 csv has been saved\n",
      "202202 reducing(group by)\n",
      "202202 reducing file has been saved\n",
      "202201 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202201 download finished\n",
      "202201 saving csv\n",
      "202201 csv has been saved\n",
      "202201 reducing(group by)\n",
      "202201 reducing file has been saved\n",
      "202112 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202112 download finished\n",
      "202112 saving csv\n",
      "202112 csv has been saved\n",
      "202112 reducing(group by)\n",
      "202112 reducing file has been saved\n",
      "202111 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202111 download finished\n",
      "202111 saving csv\n",
      "202111 csv has been saved\n",
      "202111 reducing(group by)\n",
      "202111 reducing file has been saved\n",
      "202110 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202110 download finished\n",
      "202110 saving csv\n",
      "202110 csv has been saved\n",
      "202110 reducing(group by)\n",
      "202110 reducing file has been saved\n",
      "202109 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202109 download finished\n",
      "202109 saving csv\n",
      "202109 csv has been saved\n",
      "202109 reducing(group by)\n",
      "202109 reducing file has been saved\n",
      "202108 prepare to download\n",
      "T_mrt_usage_history finished\n",
      "202108 download finished\n",
      "202108 saving csv\n",
      "202108 csv has been saved\n",
      "202108 reducing(group by)\n",
      "202108 reducing file has been saved\n",
      "202107 prepare to download\n"
     ]
    }
   ],
   "source": [
    "# url_df = E_mrt_usage_history_csvfilelist()\n",
    "# for i in range(0, 2):\n",
    "for i in range(len(url_df)-1,0,-1):\n",
    "    month = url_df.loc[i, \"年月\"]\n",
    "    url = url_df.loc[i, \"URL\"]\n",
    "    file_save_path = r\"D:\\data_engineer\\TIR_group2\\TIR101_Group2\\DA\\data\\MRT\\mrt_usage_history\"\n",
    "    # file_save_path = r\"C:\\TIR101_Group2\\DA\\data\\MRT\\mrt_usage_history\"\n",
    "    filename_full = f\"{month}_full_mrt_usage_history.csv\"\n",
    "    filename_reduce = f\"{month}_reduce_mrt_usage_history.csv\"\n",
    "    filename_full_save_path = os.path.join(file_save_path,\"full\",filename_full)\n",
    "    filename_reduce_save_path = os.path.join(file_save_path,\"reduce\",filename_reduce)\n",
    "    try:\n",
    "        print(f\"{month} prepare to download\")\n",
    "\n",
    "        T_df = T_mrt_usage_history_one_month(url=url)\n",
    "        print(f\"{month} download finished\")\n",
    "        print(f\"{month} saving csv\")\n",
    "        \n",
    "        T_df.to_csv(filename_full_save_path,encoding=\"utf-8-sig\",index=False)\n",
    "\n",
    "        print(f\"{month} csv has been saved\")\n",
    "        print(f\"{month} reducing(group by)\")\n",
    "\n",
    "        reduce_df = T_mrt_usage_history_one_month_recuce(T_df)\n",
    "        reduce_df.to_csv(filename_reduce_save_path,encoding=\"utf-8-sig\",index=False)\n",
    "        print(f\"{month} reducing file has been saved\")\n",
    "    except:\n",
    "        print(f\"ERROR {month} fail\", sep=\" \")\n",
    "        continue\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
